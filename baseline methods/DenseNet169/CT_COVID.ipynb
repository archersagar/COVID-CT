{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from shutil import copyfile\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from catalyst.data import Augmentor\n",
    "import torchxrayvision as xrv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from catalyst.data import Augmentor\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet-pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\achar\\anaconda3\\lib\\site-packages (from efficientnet-pytorch) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\achar\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\achar\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (0.8)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py): started\n",
      "  Building wheel for efficientnet-pytorch (setup.py): finished with status 'done'\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=b30183e0601d9971ccbc03d5ed7744f128c3024a895040861a8b899519c87fd3\n",
      "  Stored in directory: c:\\users\\achar\\appdata\\local\\pip\\cache\\wheels\\63\\17\\7e\\07f1c55a623c96ba9b291c5d2e4901afffb953b032c2470ca6\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('pip install --upgrade efficientnet-pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "118\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batchsize=10\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainset = CovidCTDataset(root_dir='',\n",
    "                              txt_COVID='trainCT_COVID.txt',\n",
    "                              txt_NonCOVID='trainCT_NonCOVID.txt',\n",
    "                              transform= train_transformer)\n",
    "    valset = CovidCTDataset(root_dir='',\n",
    "                              txt_COVID='valCT_COVID.txt',\n",
    "                              txt_NonCOVID='valCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    testset = CovidCTDataset(root_dir='',\n",
    "                              txt_COVID='testCT_COVID.txt',\n",
    "                              txt_NonCOVID='testCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    print(trainset.__len__())\n",
    "    print(valset.__len__())\n",
    "    print(testset.__len__())\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = None\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#        data = data[:, 0, :, :]\n",
    "#        data = data[:, None, :, :]\n",
    "#         data, targets_a, targets_b, lam = mixup_data(data, target.long(), alpha, use_cuda=True)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "#         loss = mixup_criterion(criteria, output, targets_a, targets_b, lam)\n",
    "        train_loss += criteria(output, target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
    "    \n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f.write('\\n')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#            data = data[:, 0, :, :]\n",
    "#            data = data[:, None, :, :]\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "          \n",
    "    return targetlist, scorelist, predlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#            data = data[:, 0, :, :]\n",
    "#            data = data[:, None, :, :]\n",
    "#             print(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "#             TP += ((pred == 1) & (target.long()[:, 2].view_as(pred).data == 1)).cpu().sum()\n",
    "#             TN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "# #             # FN    predict 0 label 1\n",
    "#             FN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 1)).cpu().sum()\n",
    "# #             # FP    predict 1 label 0\n",
    "#             FP += ((pred == 1) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "#             print(TP,TN,FN,FP)\n",
    "            \n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "    return targetlist, scorelist, predlist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Pass in parsed HyperOptArgumentParser to the model\n",
    "        :param hparams:\n",
    "        \"\"\"\n",
    "        super(DenseNetModel, self).__init__()\n",
    "\n",
    "        self.dense_net = xrv.models.DenseNet(num_classes=2)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.dense_net(x)\n",
    "        return logits\n",
    "    \n",
    "model = DenseNetModel()\n",
    "modelname = 'DenseNet_medical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__() # b, 3, 32, 32\n",
    "        layer1 = torch.nn.Sequential() \n",
    "        layer1.add_module('conv1', torch.nn.Conv2d(3, 32, 3, 1, padding=1))\n",
    " \n",
    "        #b, 32, 32, 32\n",
    "        layer1.add_module('relu1', torch.nn.ReLU(True)) \n",
    "        layer1.add_module('pool1', torch.nn.MaxPool2d(2, 2)) # b, 32, 16, 16 //池化为16*16\n",
    "        self.layer1 = layer1\n",
    "        layer4 = torch.nn.Sequential()\n",
    "        layer4.add_module('fc1', torch.nn.Linear(401408, 2))       \n",
    "        self.layer4 = layer4\n",
    " \n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)\n",
    "        fc_input = conv1.view(conv1.size(0), -1)\n",
    "        fc_out = self.layer4(fc_input)\n",
    " \n",
    "model = SimpleCNN()\n",
    "modelname = 'SimpleCNN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=True)\n",
    "modelname = 'ResNet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\achar/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b413f6076ed54a1591d3755849acf7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/30.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.densenet121(pretrained=True)\n",
    "modelname = 'Dense121'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to C:\\Users\\achar/.cache\\torch\\hub\\checkpoints\\densenet169-b2777c0a.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8efa729cee740ce8101ff00c7a35e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/54.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.densenet169(pretrained=True)\n",
    "modelname = 'Dense169'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\achar/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4331555d1d4d91b604b5289a555b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet50(pretrained=True)\n",
    "modelname = 'ResNet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model\n",
    "modelname = 'vgg16'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to C:\\Users\\achar/.cache\\torch\\hub\\checkpoints\\efficientnet-b0-355c32eb.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eeacb56679f4678bcb8099c60ac9001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/20.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n",
    "model = model\n",
    "modelname = 'efficientNet-b0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/43 (0%)]\tTrain Loss: 0.046469\n",
      "Train Epoch: 1 [10/43 (23%)]\tTrain Loss: 0.046015\n",
      "Train Epoch: 1 [20/43 (47%)]\tTrain Loss: 0.113983\n",
      "Train Epoch: 1 [30/43 (70%)]\tTrain Loss: 0.099260\n",
      "Train Epoch: 1 [40/43 (93%)]\tTrain Loss: 0.041590\n",
      "\n",
      "Train set: Average loss: 0.0693, Accuracy: 292/425 (69%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.26035810e-01 8.48233163e-01 4.08782005e-01 2.67349929e-02\n",
      " 2.25132909e-02 7.80970743e-03 7.31280744e-01 5.78837320e-02\n",
      " 1.84391178e-02 1.41509471e-03 2.95932009e-03 9.61415877e-04\n",
      " 5.30759804e-03 8.18640217e-02 1.21912569e-01 3.80553342e-02\n",
      " 9.47877392e-02 9.19210315e-02 2.03984097e-01 2.21883193e-01\n",
      " 3.00066173e-01 3.26840013e-01 4.17904347e-01 6.27857089e-01\n",
      " 4.27262902e-01 4.07346696e-01 4.88955587e-01 3.63048136e-01\n",
      " 1.88373417e-01 1.63271070e-01 3.05779576e-01 5.04394233e-01\n",
      " 4.82085079e-01 5.52081428e-02 2.02908646e-02 2.11400017e-02\n",
      " 2.67652832e-02 7.75662810e-02 1.32992148e-01 9.12726745e-02\n",
      " 1.12729907e-01 1.35984600e-01 9.19424370e-02 1.08318977e-01\n",
      " 1.86366260e-01 1.13230474e-01 8.80092442e-01 8.06842327e-01\n",
      " 8.86589825e-01 1.15679018e-02 8.84074330e-01 9.34377313e-03\n",
      " 2.00675707e-02 3.50878797e-02 9.65586901e-02 6.00972818e-03\n",
      " 3.03252995e-01 7.64702121e-03 6.16018474e-03 2.15594955e-02\n",
      " 7.65137374e-01 6.24286413e-01 8.22177529e-01 8.68075430e-01\n",
      " 4.32078183e-01 3.26024026e-01 1.85032859e-01 7.93246865e-01\n",
      " 6.36097848e-01 2.40507126e-01 6.23304546e-01 5.63910544e-01\n",
      " 3.90102506e-01 4.58904475e-01 3.19192261e-01 7.36512959e-01\n",
      " 9.93441463e-01 9.91923869e-01 8.82368147e-01 8.28173280e-01\n",
      " 7.24175572e-01 7.61614561e-01 8.55548203e-01 3.31910849e-01\n",
      " 2.48915657e-01 6.52190030e-01 6.87872350e-01 7.76382506e-01\n",
      " 2.37810105e-01 2.20266283e-01 3.37837130e-01 5.64993061e-02\n",
      " 4.77565154e-02 4.51689512e-01 3.26625615e-01 3.25441658e-01\n",
      " 1.48337334e-02 4.91043150e-01 2.96229154e-01 2.23029137e-01\n",
      " 1.07222416e-01 6.29072845e-01 1.06235005e-01 1.24040112e-01\n",
      " 1.69674188e-01 9.87542272e-02 3.03248972e-01 1.33769199e-01\n",
      " 2.92514622e-01 1.58359811e-01 2.26613820e-01 1.38283715e-01\n",
      " 5.93148708e-01 4.83840972e-01 1.69177175e-01 2.86008537e-01\n",
      " 3.52247477e-01 5.32371521e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "Train Epoch: 2 [0/43 (0%)]\tTrain Loss: 0.073327\n",
      "Train Epoch: 2 [10/43 (23%)]\tTrain Loss: 0.042073\n",
      "Train Epoch: 2 [20/43 (47%)]\tTrain Loss: 0.047022\n",
      "Train Epoch: 2 [30/43 (70%)]\tTrain Loss: 0.040093\n",
      "Train Epoch: 2 [40/43 (93%)]\tTrain Loss: 0.038118\n",
      "\n",
      "Train set: Average loss: 0.0524, Accuracy: 323/425 (76%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.06303429e-03 4.18903828e-02 2.94334744e-03 1.09792249e-02\n",
      " 1.39858190e-03 2.05635533e-05 1.33604044e-02 6.71881484e-03\n",
      " 1.62290380e-04 3.09151062e-03 9.76490031e-04 3.76951299e-04\n",
      " 9.65601284e-05 6.62130828e-04 1.77225180e-03 1.60270778e-03\n",
      " 2.14977819e-03 1.83509910e-04 4.61783085e-04 5.88457740e-04\n",
      " 2.13601980e-02 6.99128769e-03 5.43109365e-02 2.51312762e-01\n",
      " 3.49191725e-02 2.85738528e-01 1.09730594e-01 7.95320123e-02\n",
      " 1.76452042e-03 1.00148993e-03 1.42119139e-01 4.83922884e-02\n",
      " 1.05826063e-02 1.28888583e-03 6.31034840e-04 8.95867634e-05\n",
      " 3.18104809e-04 1.75406784e-02 3.21689770e-02 2.08192002e-02\n",
      " 1.77521594e-02 2.53599398e-02 1.53065240e-02 7.26743555e-03\n",
      " 9.13503394e-03 1.68223269e-02 5.81352413e-01 4.11397070e-01\n",
      " 8.02559733e-01 6.41350751e-04 5.88492155e-01 1.20322824e-04\n",
      " 1.36213261e-04 5.05799195e-04 7.12081464e-03 3.43048814e-05\n",
      " 1.79190949e-01 1.37238276e-05 9.08169313e-05 1.79515802e-03\n",
      " 8.45530093e-01 7.66731739e-01 9.21104372e-01 9.29318607e-01\n",
      " 6.95464686e-02 1.09395236e-01 5.51240370e-02 8.53220701e-01\n",
      " 6.66986525e-01 1.69358015e-01 2.11670488e-01 2.99047083e-01\n",
      " 5.23999296e-02 1.47240013e-01 6.93661347e-02 5.13054311e-01\n",
      " 8.16708148e-01 8.97478938e-01 7.22119868e-01 9.42665637e-01\n",
      " 8.07299376e-01 8.88762474e-01 9.66545403e-01 9.67945382e-02\n",
      " 2.13407576e-02 7.84943283e-01 8.06105614e-01 8.63610208e-01\n",
      " 5.89493709e-03 2.06059352e-01 1.34830564e-01 1.60985510e-03\n",
      " 4.86367242e-03 5.04694223e-01 1.86546162e-01 1.08375266e-01\n",
      " 2.62189951e-05 4.05500889e-01 8.78633708e-02 2.52263844e-01\n",
      " 1.71090104e-02 8.76580298e-01 1.76422973e-03 2.72741001e-02\n",
      " 2.05043852e-02 6.42141625e-02 1.28352165e-01 4.84554330e-03\n",
      " 1.96698215e-02 2.91055115e-03 8.59276429e-02 9.96626839e-02\n",
      " 8.72325182e-01 3.36067170e-01 3.65676694e-02 5.21103144e-02\n",
      " 6.93481266e-02 5.81964478e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 3 [0/43 (0%)]\tTrain Loss: 0.066145\n",
      "Train Epoch: 3 [10/43 (23%)]\tTrain Loss: 0.043673\n",
      "Train Epoch: 3 [20/43 (47%)]\tTrain Loss: 0.056554\n",
      "Train Epoch: 3 [30/43 (70%)]\tTrain Loss: 0.041897\n",
      "Train Epoch: 3 [40/43 (93%)]\tTrain Loss: 0.024589\n",
      "\n",
      "Train set: Average loss: 0.0578, Accuracy: 322/425 (76%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.09593315 0.63928783 0.05788507 0.15141448 0.08688156 0.01140108\n",
      " 0.40391508 0.05819171 0.06998651 0.03228603 0.11489034 0.00999255\n",
      " 0.06618241 0.16074696 0.28734922 0.12543997 0.22117962 0.16107896\n",
      " 0.25252229 0.19104369 0.36383036 0.4089925  0.47762012 0.59831125\n",
      " 0.48706216 0.57991451 0.53863865 0.57064325 0.23663712 0.21235667\n",
      " 0.76483256 0.69014174 0.17764865 0.18155269 0.12042277 0.1096248\n",
      " 0.16848589 0.5063051  0.62744272 0.36300787 0.28772506 0.23304121\n",
      " 0.49245539 0.43281925 0.5411011  0.33155507 0.95162404 0.86528552\n",
      " 0.93665391 0.17520225 0.98888844 0.05028814 0.29802918 0.5978182\n",
      " 0.22896481 0.12802783 0.79320562 0.11079171 0.06994365 0.23775132\n",
      " 0.97861189 0.89233637 0.97922337 0.98153323 0.72564685 0.72672212\n",
      " 0.55363184 0.94127828 0.77306926 0.95584464 0.90613937 0.93920267\n",
      " 0.69534588 0.74601394 0.76600462 0.92522776 0.99830508 0.9969632\n",
      " 0.99627894 0.99137771 0.97847694 0.97396231 0.9908818  0.88068736\n",
      " 0.28477472 0.95286566 0.89316905 0.92906779 0.37804383 0.45802566\n",
      " 0.41674203 0.04739219 0.07443052 0.69542503 0.53386432 0.65255767\n",
      " 0.18509589 0.4461917  0.21011044 0.38145781 0.07525685 0.98738551\n",
      " 0.11962374 0.25401026 0.23103388 0.71385199 0.75936353 0.24597734\n",
      " 0.30929691 0.24007213 0.25655687 0.3136037  0.73318321 0.57852554\n",
      " 0.39502215 0.32500169 0.48839501 0.31132483]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 4 [0/43 (0%)]\tTrain Loss: 0.027030\n",
      "Train Epoch: 4 [10/43 (23%)]\tTrain Loss: 0.025307\n",
      "Train Epoch: 4 [20/43 (47%)]\tTrain Loss: 0.006018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [30/43 (70%)]\tTrain Loss: 0.012416\n",
      "Train Epoch: 4 [40/43 (93%)]\tTrain Loss: 0.056540\n",
      "\n",
      "Train set: Average loss: 0.0445, Accuracy: 344/425 (81%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.08872527e-02 6.85248911e-01 4.30934951e-02 3.43764812e-01\n",
      " 1.54248908e-01 2.39743888e-02 3.99895549e-01 2.90209532e-01\n",
      " 1.36831045e-01 3.68799269e-03 2.30097352e-03 4.99985996e-04\n",
      " 1.74913299e-03 3.90250087e-01 4.84743744e-01 1.35257721e-01\n",
      " 2.93711185e-01 3.24635133e-02 1.62324727e-01 1.55594826e-01\n",
      " 3.78304213e-01 4.14327651e-01 4.79367048e-01 6.54354393e-01\n",
      " 4.35127974e-01 6.65975332e-01 5.38815141e-01 5.77321649e-01\n",
      " 5.03857791e-01 4.13868606e-01 7.10242510e-01 7.82664895e-01\n",
      " 4.23139095e-01 2.75193304e-01 1.01275384e-01 1.40943944e-01\n",
      " 2.90754348e-01 5.74558198e-01 6.44345343e-01 4.19998109e-01\n",
      " 4.41022754e-01 3.63732636e-01 4.81205761e-01 5.46507418e-01\n",
      " 5.92795849e-01 2.68957615e-01 6.99022710e-01 6.52918041e-01\n",
      " 6.88930452e-01 5.86153805e-01 7.90863216e-01 1.23942122e-01\n",
      " 2.41499335e-01 6.13899589e-01 3.04166824e-01 1.93303116e-02\n",
      " 7.67107546e-01 2.43809391e-02 1.15316678e-02 5.18247187e-01\n",
      " 8.70065153e-01 7.65258133e-01 8.53880823e-01 8.78147006e-01\n",
      " 7.38539040e-01 6.89595222e-01 5.26516080e-01 8.38058770e-01\n",
      " 8.17731142e-01 8.21126997e-01 8.30647528e-01 8.34071994e-01\n",
      " 8.17855954e-01 8.63210618e-01 7.91270792e-01 6.56937063e-01\n",
      " 8.52082193e-01 8.49194646e-01 8.61867249e-01 9.25102532e-01\n",
      " 8.92197907e-01 9.19559479e-01 9.66427684e-01 6.66674972e-01\n",
      " 1.79324284e-01 8.12647879e-01 8.45077872e-01 8.19518745e-01\n",
      " 4.95101005e-01 5.31866133e-01 5.99232256e-01 3.66226345e-01\n",
      " 2.53347635e-01 8.47042799e-01 8.32534790e-01 8.39406133e-01\n",
      " 1.98024169e-01 6.36285961e-01 3.18291724e-01 5.92002690e-01\n",
      " 2.46540934e-01 8.84368062e-01 2.05619797e-01 5.47912776e-01\n",
      " 5.30163586e-01 8.13497484e-01 8.61267865e-01 9.70117524e-02\n",
      " 3.91786098e-01 2.07679361e-01 3.78468543e-01 2.31412873e-01\n",
      " 8.34556162e-01 6.88257396e-01 6.73476040e-01 5.66445351e-01\n",
      " 1.83320329e-01 4.69022483e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 5 [0/43 (0%)]\tTrain Loss: 0.039628\n",
      "Train Epoch: 5 [10/43 (23%)]\tTrain Loss: 0.028888\n",
      "Train Epoch: 5 [20/43 (47%)]\tTrain Loss: 0.069003\n",
      "Train Epoch: 5 [30/43 (70%)]\tTrain Loss: 0.072530\n",
      "Train Epoch: 5 [40/43 (93%)]\tTrain Loss: 0.028029\n",
      "\n",
      "Train set: Average loss: 0.0411, Accuracy: 355/425 (84%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.02405285e-03 6.30602121e-01 5.27351126e-02 5.93576916e-02\n",
      " 3.41305360e-02 5.95924867e-05 2.62906909e-01 3.10813468e-02\n",
      " 4.25119288e-02 3.59874335e-04 1.97015032e-02 4.34327922e-05\n",
      " 5.70893660e-02 8.13153386e-02 1.83705956e-01 1.99648384e-02\n",
      " 1.11448891e-01 1.65070109e-02 4.41918299e-02 3.62363644e-02\n",
      " 1.17288411e-01 4.69486922e-01 2.30646357e-01 6.20541811e-01\n",
      " 6.04290307e-01 3.70338202e-01 3.13626289e-01 3.42530012e-01\n",
      " 6.52033836e-02 5.46801277e-02 4.07080501e-01 3.11261028e-01\n",
      " 4.16017398e-02 6.02862015e-02 4.32232693e-02 9.41168237e-03\n",
      " 5.26034161e-02 1.42498747e-01 4.19431895e-01 2.98269004e-01\n",
      " 2.98366666e-01 3.80946904e-01 1.15170851e-01 1.59902930e-01\n",
      " 1.44583404e-01 9.30159241e-02 7.76648104e-01 6.04308009e-01\n",
      " 7.71520078e-01 6.06764853e-02 9.67945099e-01 6.53828681e-03\n",
      " 3.30844671e-02 1.85845464e-01 7.32708722e-02 2.25378480e-02\n",
      " 7.58813858e-01 1.70279294e-02 1.15576072e-03 3.25980000e-02\n",
      " 9.95507836e-01 9.68599916e-01 9.86240447e-01 9.84960616e-01\n",
      " 6.18395805e-01 8.11322033e-01 6.95876300e-01 9.82827425e-01\n",
      " 9.75857735e-01 4.26015824e-01 5.99255085e-01 6.61684334e-01\n",
      " 5.59563637e-01 8.31348181e-01 6.84440553e-01 7.60512888e-01\n",
      " 9.94842470e-01 9.95665610e-01 9.70350564e-01 9.87816274e-01\n",
      " 9.72535431e-01 9.83962476e-01 9.98360455e-01 6.99580431e-01\n",
      " 3.20755064e-01 8.90409946e-01 9.70520675e-01 9.55710471e-01\n",
      " 1.33155674e-01 8.49137127e-01 5.82865894e-01 4.75544520e-02\n",
      " 2.90019121e-02 9.76077795e-01 9.73381877e-01 9.68737185e-01\n",
      " 1.82654765e-02 8.46933186e-01 3.10734689e-01 8.24195564e-01\n",
      " 1.58476070e-01 9.90232229e-01 1.24785215e-01 1.54360265e-01\n",
      " 2.02457890e-01 2.08014548e-01 8.34993422e-01 1.73049152e-01\n",
      " 3.56085628e-01 9.69146714e-02 7.05107272e-01 5.24703920e-01\n",
      " 9.92469609e-01 7.84471273e-01 5.96864462e-01 4.23458576e-01\n",
      " 5.74419916e-01 8.37340117e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 6 [0/43 (0%)]\tTrain Loss: 0.020633\n",
      "Train Epoch: 6 [10/43 (23%)]\tTrain Loss: 0.035084\n",
      "Train Epoch: 6 [20/43 (47%)]\tTrain Loss: 0.017093\n",
      "Train Epoch: 6 [30/43 (70%)]\tTrain Loss: 0.034588\n",
      "Train Epoch: 6 [40/43 (93%)]\tTrain Loss: 0.018683\n",
      "\n",
      "Train set: Average loss: 0.0338, Accuracy: 369/425 (87%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.53669238e-01 5.79595029e-01 1.28508136e-01 4.34034944e-01\n",
      " 5.48177242e-01 1.64620560e-02 6.05519891e-01 3.07199538e-01\n",
      " 1.69189140e-01 1.42392233e-01 7.03197241e-01 1.17036767e-01\n",
      " 5.43630481e-01 1.13271423e-01 4.63365346e-01 5.02065850e-05\n",
      " 1.18352838e-01 1.89416945e-01 4.01813656e-01 2.52439022e-01\n",
      " 5.40141761e-01 8.37984264e-01 5.82658768e-01 9.11103964e-01\n",
      " 8.58528852e-01 5.96942067e-01 6.98689640e-01 4.83609110e-01\n",
      " 1.90074652e-01 1.78854913e-01 4.53887939e-01 2.52036422e-01\n",
      " 3.33571387e-03 7.60420412e-02 2.78518372e-03 3.79101709e-02\n",
      " 2.45491102e-01 2.64179051e-01 5.20719051e-01 7.96580687e-02\n",
      " 1.66850299e-01 1.32889077e-01 1.93782687e-01 2.55136102e-01\n",
      " 4.22594607e-01 6.60568178e-02 4.06326503e-01 4.16126162e-01\n",
      " 5.33976972e-01 4.39945728e-01 8.97136331e-01 1.01267338e-01\n",
      " 2.12495625e-01 3.25830847e-01 1.40679911e-01 1.32203534e-01\n",
      " 8.45077813e-01 8.29266533e-02 7.86543638e-02 1.75686583e-01\n",
      " 9.33402956e-01 9.21014965e-01 9.59686697e-01 9.45316255e-01\n",
      " 7.84429312e-01 9.50519919e-01 9.49249387e-01 9.85158503e-01\n",
      " 9.96845424e-01 7.55216539e-01 3.94707441e-01 3.88935149e-01\n",
      " 8.00960481e-01 9.37235475e-01 7.82075703e-01 5.52000582e-01\n",
      " 9.70430076e-01 9.65023398e-01 9.08391058e-01 9.62541640e-01\n",
      " 9.26307857e-01 9.64637160e-01 9.95399058e-01 8.03502023e-01\n",
      " 2.47045591e-01 5.48415244e-01 9.18148756e-01 8.91688347e-01\n",
      " 5.51476121e-01 9.65506494e-01 8.92532647e-01 4.54929829e-01\n",
      " 2.99274862e-01 9.97380555e-01 9.98045921e-01 9.98283803e-01\n",
      " 6.67350590e-01 8.22519720e-01 4.11872447e-01 8.70996773e-01\n",
      " 4.08447832e-01 9.86632288e-01 3.85611832e-01 4.91142780e-01\n",
      " 6.10691428e-01 1.91260114e-01 9.02886152e-01 4.09301370e-01\n",
      " 8.73032987e-01 3.54653329e-01 8.78787994e-01 6.80225730e-01\n",
      " 9.99636650e-01 9.33852673e-01 6.81795716e-01 5.37420809e-01\n",
      " 8.01515400e-01 7.30375290e-01]\n",
      "predict [0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [0/43 (0%)]\tTrain Loss: 0.028306\n",
      "Train Epoch: 7 [10/43 (23%)]\tTrain Loss: 0.001145\n",
      "Train Epoch: 7 [20/43 (47%)]\tTrain Loss: 0.044400\n",
      "Train Epoch: 7 [30/43 (70%)]\tTrain Loss: 0.021203\n",
      "Train Epoch: 7 [40/43 (93%)]\tTrain Loss: 0.015968\n",
      "\n",
      "Train set: Average loss: 0.0281, Accuracy: 373/425 (88%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.64390798e-04 4.57734674e-01 5.50934160e-03 4.54682595e-04\n",
      " 2.07613036e-03 7.14830037e-07 4.79010493e-01 6.88979053e-04\n",
      " 7.95735861e-04 4.28028638e-03 3.76633108e-01 2.26993812e-03\n",
      " 2.58264393e-01 3.16324174e-01 2.85411865e-01 1.10381541e-06\n",
      " 2.68566143e-02 5.71266690e-04 1.82026103e-01 9.29132476e-02\n",
      " 3.52794707e-01 6.14917934e-01 7.19321072e-01 8.27551901e-01\n",
      " 6.79579675e-01 8.75103831e-01 9.47980046e-01 6.39954329e-01\n",
      " 7.36307725e-02 2.30109438e-01 5.42612314e-01 3.88586313e-01\n",
      " 2.90050600e-02 3.59619409e-02 2.03464864e-04 1.58046337e-03\n",
      " 4.32642326e-02 6.27250643e-03 3.74309927e-01 3.24356034e-02\n",
      " 8.26625377e-02 1.44453168e-01 7.24473794e-05 1.80642083e-01\n",
      " 1.57882810e-01 9.80541036e-02 5.89010060e-01 5.41658103e-01\n",
      " 7.12690234e-01 4.94374186e-01 9.10232008e-01 8.84025794e-05\n",
      " 5.79905936e-05 7.17559382e-02 1.02040410e-01 4.10078000e-03\n",
      " 4.08317953e-01 2.92133261e-03 1.29074760e-04 8.56142957e-03\n",
      " 9.87612426e-01 9.62313294e-01 9.82931316e-01 9.92118299e-01\n",
      " 4.59674090e-01 4.95766729e-01 1.29769102e-01 9.78244364e-01\n",
      " 9.64790702e-01 8.67927134e-01 9.33057308e-01 8.91038954e-01\n",
      " 8.21155548e-01 9.24992204e-01 7.52781332e-01 7.80950487e-01\n",
      " 9.95704114e-01 9.97297943e-01 9.98598278e-01 9.93405342e-01\n",
      " 9.98002589e-01 9.95949030e-01 9.99782383e-01 7.30176926e-01\n",
      " 5.92336357e-01 8.08808088e-01 9.16473925e-01 8.95822942e-01\n",
      " 1.25202671e-01 9.83852386e-01 9.67741609e-01 3.76525708e-03\n",
      " 5.39858520e-05 9.45042908e-01 9.07254338e-01 8.78265977e-01\n",
      " 2.64830049e-03 9.38370824e-01 7.47044683e-01 9.29008126e-01\n",
      " 3.65163177e-01 9.97268319e-01 4.41585332e-01 1.16731375e-01\n",
      " 2.12857485e-01 2.58163244e-01 8.09667051e-01 9.85287577e-02\n",
      " 6.71226144e-01 8.17675963e-02 9.60843325e-01 9.18815076e-01\n",
      " 9.96587157e-01 8.41265500e-01 8.02850068e-01 4.64724541e-01\n",
      " 8.85965109e-01 9.04992223e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 8 [0/43 (0%)]\tTrain Loss: 0.019527\n",
      "Train Epoch: 8 [10/43 (23%)]\tTrain Loss: 0.026894\n",
      "Train Epoch: 8 [20/43 (47%)]\tTrain Loss: 0.013303\n",
      "Train Epoch: 8 [30/43 (70%)]\tTrain Loss: 0.118324\n",
      "Train Epoch: 8 [40/43 (93%)]\tTrain Loss: 0.046368\n",
      "\n",
      "Train set: Average loss: 0.0437, Accuracy: 350/425 (82%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.02575112e-03 6.81249857e-01 4.16125000e-01 1.45458400e-01\n",
      " 3.15645374e-02 1.92414562e-04 7.54668176e-01 1.20732427e-01\n",
      " 3.91258299e-02 3.41447373e-03 1.36743680e-01 1.29002932e-04\n",
      " 6.37166724e-02 4.77831095e-01 6.66044354e-01 5.49450517e-02\n",
      " 1.87767923e-01 7.47356713e-02 4.08058375e-01 4.52166319e-01\n",
      " 4.27439630e-01 6.01729393e-01 6.34275973e-01 6.18866444e-01\n",
      " 5.64714611e-01 6.37562156e-01 4.17900294e-01 5.35464644e-01\n",
      " 4.54471916e-01 5.45416176e-01 6.97140753e-01 7.05756724e-01\n",
      " 5.57067871e-01 4.02396232e-01 2.96527982e-01 9.79733616e-02\n",
      " 2.60367811e-01 4.98672634e-01 5.84444940e-01 5.14345109e-01\n",
      " 5.86256802e-01 5.33053577e-01 3.88384581e-01 6.42595589e-01\n",
      " 6.55934393e-01 6.42968714e-01 6.89488709e-01 7.40507841e-01\n",
      " 7.86973357e-01 3.55314463e-02 7.70538688e-01 4.21782136e-02\n",
      " 1.71244338e-01 2.30760559e-01 1.41043901e-01 1.91472739e-01\n",
      " 5.28115511e-01 1.44521028e-01 7.99721165e-04 6.34521484e-01\n",
      " 8.47218633e-01 8.08401048e-01 8.76325667e-01 8.62046659e-01\n",
      " 7.79345810e-01 7.89469600e-01 7.29153156e-01 8.86942565e-01\n",
      " 7.68536985e-01 5.11307836e-01 7.36176968e-01 7.38638341e-01\n",
      " 7.32559025e-01 6.17216527e-01 7.44870067e-01 8.22195411e-01\n",
      " 9.95105743e-01 9.96546924e-01 9.33702171e-01 9.06822443e-01\n",
      " 8.61924052e-01 8.60609412e-01 9.08509791e-01 6.60297871e-01\n",
      " 6.13464653e-01 8.35858822e-01 8.24195981e-01 8.20837200e-01\n",
      " 5.14587104e-01 6.14652634e-01 6.09400153e-01 2.01211765e-01\n",
      " 4.91284519e-01 7.32789457e-01 4.16136682e-01 5.41239083e-01\n",
      " 1.70357242e-01 5.71832418e-01 3.35735828e-01 6.18505538e-01\n",
      " 5.22121824e-02 8.60316753e-01 5.11804402e-01 4.31398690e-01\n",
      " 2.55434394e-01 5.02414048e-01 4.92307603e-01 3.44976366e-01\n",
      " 2.43028149e-01 4.98579480e-02 1.83314607e-01 8.38152617e-02\n",
      " 4.58766490e-01 6.48965538e-01 5.99636793e-01 6.81292117e-01\n",
      " 6.24671459e-01 7.17765212e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 9 [0/43 (0%)]\tTrain Loss: 0.068270\n",
      "Train Epoch: 9 [10/43 (23%)]\tTrain Loss: 0.030495\n",
      "Train Epoch: 9 [20/43 (47%)]\tTrain Loss: 0.028135\n",
      "Train Epoch: 9 [30/43 (70%)]\tTrain Loss: 0.035509\n",
      "Train Epoch: 9 [40/43 (93%)]\tTrain Loss: 0.016791\n",
      "\n",
      "Train set: Average loss: 0.0433, Accuracy: 349/425 (82%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.00794893 0.66811031 0.14814854 0.07263122 0.02355894 0.01133079\n",
      " 0.44449398 0.06070435 0.06004163 0.02843329 0.02249613 0.00119049\n",
      " 0.0121775  0.27295437 0.46456912 0.01689045 0.0415627  0.00762875\n",
      " 0.08096655 0.1111901  0.16047455 0.29956645 0.32906207 0.52745932\n",
      " 0.27363303 0.46546218 0.35388261 0.43613049 0.10687911 0.08579126\n",
      " 0.30817431 0.0850385  0.05344377 0.09590513 0.05194267 0.00817607\n",
      " 0.02449622 0.374605   0.50254381 0.47419316 0.34834018 0.35831681\n",
      " 0.43235645 0.51762319 0.25133568 0.49383789 0.45114481 0.45261341\n",
      " 0.47057962 0.13885522 0.71773291 0.00928238 0.0600068  0.13802166\n",
      " 0.06847278 0.06725565 0.66856664 0.02536993 0.02960961 0.13196068\n",
      " 0.97069496 0.89592916 0.95631468 0.94992316 0.60161543 0.75703543\n",
      " 0.55668432 0.91931772 0.81916243 0.80592179 0.87129945 0.82400548\n",
      " 0.52309781 0.58835691 0.55663407 0.75169671 0.97451198 0.98166716\n",
      " 0.93684214 0.9661746  0.93341219 0.94174206 0.99031079 0.46136814\n",
      " 0.26851434 0.87592387 0.82457495 0.69902515 0.20058519 0.48979351\n",
      " 0.49585581 0.0835575  0.0867346  0.61443019 0.34252167 0.38570186\n",
      " 0.01745647 0.56171757 0.20245068 0.46981525 0.20616005 0.96499091\n",
      " 0.1357362  0.20064892 0.14015077 0.48146176 0.72025108 0.19939041\n",
      " 0.29023761 0.15486024 0.2302175  0.28132558 0.73254305 0.53154302\n",
      " 0.48630434 0.5054847  0.23511332 0.29239377]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 10 [0/43 (0%)]\tTrain Loss: 0.057591\n",
      "Train Epoch: 10 [10/43 (23%)]\tTrain Loss: 0.031468\n",
      "Train Epoch: 10 [20/43 (47%)]\tTrain Loss: 0.036001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [30/43 (70%)]\tTrain Loss: 0.012449\n",
      "Train Epoch: 10 [40/43 (93%)]\tTrain Loss: 0.004247\n",
      "\n",
      "Train set: Average loss: 0.0329, Accuracy: 368/425 (87%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.04291589e-03 3.20755243e-01 4.56867390e-04 6.50949031e-02\n",
      " 1.04499161e-02 4.91582381e-04 1.61060795e-01 3.12996916e-02\n",
      " 4.04614285e-02 2.32834652e-01 5.29093206e-01 3.07637099e-02\n",
      " 5.83235025e-01 2.50843409e-02 5.75202256e-02 3.39295832e-03\n",
      " 1.09288990e-01 2.80338898e-02 1.04472339e-01 1.15376569e-01\n",
      " 3.53913397e-01 6.43262208e-01 7.00767636e-01 8.37021708e-01\n",
      " 5.97412050e-01 8.90908480e-01 6.41505718e-01 7.13552773e-01\n",
      " 4.44901222e-03 4.51634545e-03 8.43679309e-01 5.53540468e-01\n",
      " 2.09958274e-02 5.71038723e-02 2.45886501e-02 6.06188038e-03\n",
      " 3.36366966e-02 7.87438750e-01 9.06912208e-01 8.43766034e-01\n",
      " 7.46747196e-01 6.67587638e-01 7.60584652e-01 7.17039347e-01\n",
      " 4.82685305e-02 5.92698097e-01 9.43702281e-01 8.82613719e-01\n",
      " 8.39812756e-01 7.99780428e-01 9.93803859e-01 5.10059409e-02\n",
      " 1.23527117e-01 3.35480809e-01 1.22342696e-02 5.35832569e-02\n",
      " 9.45914924e-01 2.31783651e-02 7.31544718e-02 9.09573585e-02\n",
      " 9.97743607e-01 9.84673500e-01 9.98216331e-01 9.98851776e-01\n",
      " 7.43713081e-01 9.76865411e-01 9.87931132e-01 9.93311048e-01\n",
      " 9.88863111e-01 9.52121675e-01 8.90054047e-01 7.32142866e-01\n",
      " 8.30410957e-01 9.50012207e-01 8.14065278e-01 9.95456457e-01\n",
      " 9.99609888e-01 9.99552786e-01 9.85037744e-01 9.99577582e-01\n",
      " 9.99058902e-01 9.99623418e-01 9.99993920e-01 9.07780468e-01\n",
      " 4.03249741e-01 9.26312566e-01 9.75168467e-01 9.45102274e-01\n",
      " 2.06224978e-01 9.82751787e-01 9.84228015e-01 3.45882356e-01\n",
      " 1.71777695e-01 9.99169827e-01 9.92032647e-01 9.91953075e-01\n",
      " 7.27688745e-02 9.15270984e-01 4.52953316e-02 6.90427005e-01\n",
      " 2.04691470e-01 9.99909878e-01 5.62283635e-01 3.07439446e-01\n",
      " 5.91686852e-02 7.72887945e-01 9.87783253e-01 5.76821089e-01\n",
      " 7.02255845e-01 2.41738677e-01 7.48405933e-01 7.98538744e-01\n",
      " 9.96990800e-01 9.12765980e-01 6.63826942e-01 4.24620777e-01\n",
      " 7.87962794e-01 6.95238650e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 40 TN= 50 FN= 18 FP= 10\n",
      "TP+FP 50\n",
      "precision 0.8\n",
      "recall 0.6896551724137931\n",
      "F1 0.7407407407407408\n",
      "acc 0.7627118644067796\n",
      "AUCp 0.7614942528735633\n",
      "AUC 0.8405172413793104\n",
      "\n",
      " The epoch is 10, average recall: 0.6897, average precision: 0.8000,average F1: 0.7407, average accuracy: 0.7627, average AUC: 0.8405\n",
      "Train Epoch: 11 [0/43 (0%)]\tTrain Loss: 0.011859\n",
      "Train Epoch: 11 [10/43 (23%)]\tTrain Loss: 0.002376\n",
      "Train Epoch: 11 [20/43 (47%)]\tTrain Loss: 0.016504\n",
      "Train Epoch: 11 [30/43 (70%)]\tTrain Loss: 0.023333\n",
      "Train Epoch: 11 [40/43 (93%)]\tTrain Loss: 0.021450\n",
      "\n",
      "Train set: Average loss: 0.0239, Accuracy: 391/425 (92%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.03973725e-03 9.92670178e-01 7.32740760e-03 1.21924065e-01\n",
      " 6.35089502e-02 1.61523130e-04 9.40437555e-01 1.45696670e-01\n",
      " 4.25146334e-02 6.83135092e-01 9.43685293e-01 2.46853396e-01\n",
      " 9.87048328e-01 6.88664988e-02 2.84506261e-01 4.59174998e-03\n",
      " 4.86656725e-01 5.22555232e-01 7.11549103e-01 7.59761214e-01\n",
      " 8.39533031e-01 9.59939957e-01 9.86456156e-01 9.21520948e-01\n",
      " 9.66393888e-01 9.94251609e-01 9.90667760e-01 9.52745438e-01\n",
      " 1.02465279e-01 2.04654988e-02 8.65851223e-01 1.39457405e-01\n",
      " 2.25382009e-05 7.44160593e-01 5.16054869e-01 1.65348705e-02\n",
      " 1.54888660e-01 8.90995800e-01 9.74725544e-01 9.88346040e-01\n",
      " 9.53593314e-01 9.84171808e-01 6.84078634e-01 9.80559051e-01\n",
      " 8.30018282e-01 7.41559505e-01 9.99506593e-01 9.84342933e-01\n",
      " 9.96393979e-01 9.92490351e-01 9.99930024e-01 5.25925994e-01\n",
      " 7.77008533e-01 7.72096395e-01 2.82323211e-01 4.65824157e-01\n",
      " 9.67976928e-01 6.64048791e-01 4.06783283e-01 3.65417480e-01\n",
      " 9.99967098e-01 9.99669552e-01 9.99988556e-01 9.99996066e-01\n",
      " 9.63674247e-01 9.95001137e-01 9.85711634e-01 9.99996305e-01\n",
      " 9.99881268e-01 7.48646498e-01 4.58712369e-01 1.59020767e-01\n",
      " 9.78461742e-01 9.89391446e-01 9.40806389e-01 9.98144984e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.98884022e-01 9.99997735e-01\n",
      " 9.99976039e-01 9.99998450e-01 1.00000000e+00 9.86508489e-01\n",
      " 6.79909408e-01 9.89872217e-01 9.95222986e-01 9.98164237e-01\n",
      " 6.42610729e-01 9.99868631e-01 9.99875665e-01 8.62089515e-01\n",
      " 1.22291341e-01 9.99997973e-01 9.99978542e-01 9.99971747e-01\n",
      " 9.16087210e-01 9.75170612e-01 4.16806340e-01 9.80010569e-01\n",
      " 4.77135539e-01 9.99999523e-01 8.85676444e-01 5.14856279e-01\n",
      " 1.33353770e-01 9.86748457e-01 9.92304027e-01 9.83582914e-01\n",
      " 9.95943248e-01 9.66165781e-01 9.95966911e-01 9.64264572e-01\n",
      " 1.00000000e+00 9.98872459e-01 9.70764160e-01 7.78675616e-01\n",
      " 9.97842789e-01 7.61121511e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 12 [0/43 (0%)]\tTrain Loss: 0.016255\n",
      "Train Epoch: 12 [10/43 (23%)]\tTrain Loss: 0.011418\n",
      "Train Epoch: 12 [20/43 (47%)]\tTrain Loss: 0.032293\n",
      "Train Epoch: 12 [30/43 (70%)]\tTrain Loss: 0.012853\n",
      "Train Epoch: 12 [40/43 (93%)]\tTrain Loss: 0.064548\n",
      "\n",
      "Train set: Average loss: 0.0329, Accuracy: 373/425 (88%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.59423220e-01 1.97604881e-03 5.02650775e-18 5.46521023e-02\n",
      " 8.42788145e-02 1.46261751e-04 8.04223191e-07 2.32831717e-01\n",
      " 2.24933520e-01 2.47692466e-01 4.45767432e-01 9.87196639e-02\n",
      " 2.75832236e-01 6.93462729e-01 6.10563636e-01 5.84163293e-02\n",
      " 2.80074596e-01 9.84195843e-02 4.30668890e-01 3.85469943e-01\n",
      " 7.28588164e-01 8.26629341e-01 8.06942880e-01 9.46441293e-01\n",
      " 8.69460702e-01 9.48870480e-01 9.55995023e-01 8.00726771e-01\n",
      " 2.60804117e-01 6.26982674e-02 3.72770756e-01 4.90716510e-02\n",
      " 3.27884142e-27 2.70034403e-01 1.40415922e-01 2.64886580e-02\n",
      " 1.19387858e-01 7.51124203e-01 9.52923536e-01 8.63562226e-01\n",
      " 6.62993371e-01 6.41838372e-01 6.30132854e-01 8.48466873e-01\n",
      " 4.23074335e-01 5.83524823e-01 9.90262389e-01 9.40931559e-01\n",
      " 9.91321146e-01 9.22817767e-01 9.98753548e-01 3.05435574e-03\n",
      " 9.08376351e-02 5.08070476e-02 1.47477403e-01 2.07448043e-02\n",
      " 9.29703653e-01 4.10734825e-02 1.28932893e-01 6.98866090e-03\n",
      " 9.99898076e-01 9.98499393e-01 9.99975204e-01 9.99995589e-01\n",
      " 8.73812795e-01 9.37728226e-01 9.69573796e-01 9.99627352e-01\n",
      " 9.96488214e-01 9.86416578e-01 9.98119771e-01 9.97826040e-01\n",
      " 8.83260429e-01 9.65593636e-01 9.03716922e-01 9.99657750e-01\n",
      " 9.99991536e-01 9.99984503e-01 9.99970078e-01 9.99973655e-01\n",
      " 9.99935746e-01 9.99968052e-01 9.99999642e-01 9.84663665e-01\n",
      " 8.26145291e-01 9.97582674e-01 9.98239279e-01 9.98860478e-01\n",
      " 4.50458586e-01 9.54123497e-01 9.66321170e-01 6.94416314e-02\n",
      " 5.12514124e-03 9.92168605e-01 9.82269049e-01 9.89757538e-01\n",
      " 2.54112214e-01 9.41135287e-01 5.56224644e-01 8.81417036e-01\n",
      " 7.22859979e-01 9.99999166e-01 8.47413003e-01 5.24811625e-01\n",
      " 6.47433519e-01 9.54145074e-01 9.68228519e-01 6.14834785e-01\n",
      " 7.87744582e-01 6.54695868e-01 8.50375414e-01 6.24228716e-01\n",
      " 9.92439151e-01 9.03482258e-01 9.44221497e-01 8.36756587e-01\n",
      " 9.41580534e-01 8.02817941e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [0/43 (0%)]\tTrain Loss: 0.014262\n",
      "Train Epoch: 13 [10/43 (23%)]\tTrain Loss: 0.047371\n",
      "Train Epoch: 13 [20/43 (47%)]\tTrain Loss: 0.120676\n",
      "Train Epoch: 13 [30/43 (70%)]\tTrain Loss: 0.012107\n",
      "Train Epoch: 13 [40/43 (93%)]\tTrain Loss: 0.051430\n",
      "\n",
      "Train set: Average loss: 0.0210, Accuracy: 394/425 (93%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.52335628e-03 1.00000000e+00 4.08131480e-02 3.78758639e-01\n",
      " 4.97268677e-01 2.36369416e-07 1.00000000e+00 6.17180645e-01\n",
      " 7.67255902e-01 2.30669882e-02 8.15916419e-01 1.27370865e-03\n",
      " 9.74044800e-01 5.10294437e-01 3.04851890e-01 6.99434313e-05\n",
      " 4.06582560e-03 8.27041082e-03 8.70321412e-04 9.96180903e-03\n",
      " 4.22698930e-02 9.31643665e-01 9.75955963e-01 9.81594443e-01\n",
      " 9.57001269e-01 9.92798924e-01 9.75165546e-01 7.23544240e-01\n",
      " 2.04350962e-03 1.87973346e-04 6.22311980e-02 2.64694184e-01\n",
      " 8.42850804e-02 7.74918264e-03 1.79632357e-03 1.35049544e-04\n",
      " 3.50624463e-03 9.86552775e-01 9.99570906e-01 9.77041781e-01\n",
      " 7.46771634e-01 9.19996500e-01 6.77221954e-01 9.59783673e-01\n",
      " 2.38997057e-01 1.37260869e-01 9.99764740e-01 9.90891755e-01\n",
      " 9.99784768e-01 9.83972311e-01 9.99999762e-01 1.19803485e-03\n",
      " 8.52407422e-04 1.62211224e-01 3.79347155e-04 6.56235443e-06\n",
      " 9.66023505e-01 2.62890186e-04 6.78031053e-03 2.72751291e-04\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 6.11428201e-01 9.99537706e-01 9.99519944e-01 1.00000000e+00\n",
      " 9.99999642e-01 9.97586846e-01 9.99694586e-01 9.98361170e-01\n",
      " 8.68473113e-01 9.86770391e-01 6.55120552e-01 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99998450e-01 9.99997854e-01 1.00000000e+00 9.99987245e-01\n",
      " 8.35253000e-01 9.99992847e-01 9.99997139e-01 9.99999046e-01\n",
      " 1.27701582e-02 9.99573171e-01 9.95621383e-01 9.09312487e-01\n",
      " 1.68171316e-01 9.99957800e-01 9.99624252e-01 9.99785244e-01\n",
      " 1.97460987e-02 9.95779753e-01 4.64177072e-01 9.65964198e-01\n",
      " 5.24630249e-01 1.00000000e+00 9.95262504e-01 1.61532611e-02\n",
      " 1.68149006e-02 3.30599487e-01 6.40007734e-01 7.67244399e-01\n",
      " 7.00279891e-01 8.44801128e-01 9.07833517e-01 6.55339956e-01\n",
      " 9.99978065e-01 9.98072863e-01 9.86348867e-01 9.77014780e-01\n",
      " 9.98989761e-01 9.78699982e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 14 [0/43 (0%)]\tTrain Loss: 0.001100\n",
      "Train Epoch: 14 [10/43 (23%)]\tTrain Loss: 0.026850\n",
      "Train Epoch: 14 [20/43 (47%)]\tTrain Loss: 0.003882\n",
      "Train Epoch: 14 [30/43 (70%)]\tTrain Loss: 0.021948\n",
      "Train Epoch: 14 [40/43 (93%)]\tTrain Loss: 0.004857\n",
      "\n",
      "Train set: Average loss: 0.0242, Accuracy: 382/425 (90%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.91287532e-03 9.99763548e-01 2.30186552e-01 4.76416498e-01\n",
      " 2.26510048e-01 5.85751604e-06 9.98491883e-01 6.16715439e-02\n",
      " 1.46344259e-01 1.98568776e-01 9.65984762e-01 1.71076823e-02\n",
      " 9.18277264e-01 8.12866330e-01 7.15404212e-01 3.84291896e-04\n",
      " 2.64033163e-03 1.12659425e-01 6.49661049e-02 6.37319013e-02\n",
      " 1.66988254e-01 7.53241539e-01 2.69140005e-01 7.11661398e-01\n",
      " 6.28035188e-01 8.95027459e-01 9.14652884e-01 5.33297837e-01\n",
      " 1.63284428e-02 2.83935782e-03 6.51858330e-01 5.63290119e-01\n",
      " 1.78523733e-05 6.01991033e-03 7.90375401e-04 7.29106323e-05\n",
      " 1.65185612e-03 5.06005883e-01 9.57585931e-01 9.21089590e-01\n",
      " 7.46726751e-01 8.45698774e-01 6.48439676e-02 2.87077069e-01\n",
      " 1.94512442e-01 3.48977834e-01 9.17783380e-01 7.30430782e-01\n",
      " 9.20130074e-01 9.95457411e-01 9.97943819e-01 1.27373892e-03\n",
      " 4.29341523e-03 5.11304736e-02 2.54069775e-01 1.32786650e-02\n",
      " 9.53640163e-01 3.33528072e-02 2.34110896e-02 1.80358510e-03\n",
      " 9.99990106e-01 9.99920011e-01 9.99984980e-01 9.99996305e-01\n",
      " 6.22014761e-01 9.84251916e-01 9.67972219e-01 9.99708951e-01\n",
      " 9.99917984e-01 9.45842624e-01 9.76293445e-01 8.84973764e-01\n",
      " 9.39397871e-01 9.87890244e-01 8.62174451e-01 9.32508945e-01\n",
      " 1.00000000e+00 1.00000000e+00 8.71244907e-01 9.99605954e-01\n",
      " 9.99839664e-01 9.99918699e-01 9.99999881e-01 9.15040255e-01\n",
      " 5.49852967e-01 9.71629500e-01 9.79382873e-01 9.95106697e-01\n",
      " 4.83738929e-02 9.96090472e-01 9.85853553e-01 4.51207548e-01\n",
      " 9.71909612e-02 9.71800804e-01 9.97480929e-01 9.77121770e-01\n",
      " 1.65125251e-01 9.91120517e-01 8.70983899e-01 9.54517901e-01\n",
      " 8.40168953e-01 9.99990940e-01 9.71168399e-01 8.81061077e-01\n",
      " 8.55142295e-01 9.98012424e-01 9.98421550e-01 5.83655894e-01\n",
      " 8.50867629e-01 9.00525093e-01 9.22661722e-01 8.81843150e-01\n",
      " 9.99716222e-01 8.47778261e-01 9.49960709e-01 5.50854921e-01\n",
      " 9.87310171e-01 7.86382020e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 15 [0/43 (0%)]\tTrain Loss: 0.022920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-3c0c9949b79b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtotal_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_epoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mtargetlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorelist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-2dba95d6ad62>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(optimizer, epoch)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcriteria\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "bs = 10\n",
    "votenum = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "#scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    targetlist, scorelist, predlist = val(epoch)\n",
    "    print('target',targetlist)\n",
    "    print('score',scorelist)\n",
    "    print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if epoch == total_epoch:\n",
    "        torch.save(model.state_dict(), \"model_backup/{}.pt\".format(modelname))  \n",
    "        \n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP= 78 TN= 73 FN= 27 FP= 25\n",
      "TP+FP 103\n",
      "precision 0.7572815533980582\n",
      "recall 0.7428571428571429\n",
      "F1 0.7499999999999999\n",
      "acc 0.7438423645320197\n",
      "AUC 0.8311953352769679\n",
      "TP= 78 TN= 73 FN= 27 FP= 25\n",
      "TP+FP 103\n",
      "precision 0.7572815533980582\n",
      "recall 0.7428571428571429\n",
      "F1 0.7499999999999999\n",
      "acc 0.7438423645320197\n",
      "AUC 0.8311953352769679\n",
      "TP= 78 TN= 73 FN= 27 FP= 25\n",
      "TP+FP 103\n",
      "precision 0.7572815533980582\n",
      "recall 0.7428571428571429\n",
      "F1 0.7499999999999999\n",
      "acc 0.7438423645320197\n",
      "AUC 0.8311953352769679\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-3722c2227c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_epoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtargetlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorelist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#     print('target',targetlist)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#     print('score',scorelist)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-861210823e87>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#            data = data[:, None, :, :]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#             print(target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 440\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bs = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    \n",
    "    targetlist, scorelist, predlist = test(epoch)\n",
    "#     print('target',targetlist)\n",
    "#     print('score',scorelist)\n",
    "#     print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "    \n",
    "    TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
    "    TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
    "    FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
    "    FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
    "\n",
    "    print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "    print('TP+FP',TP+FP)\n",
    "    p = TP / (TP + FP)\n",
    "    print('precision',p)\n",
    "    p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    print('recall',r)\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print('F1',F1)\n",
    "    print('acc',acc)\n",
    "    AUC = roc_auc_score(targetlist, vote_score)\n",
    "    print('AUC', AUC)\n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        \n",
    "#         print('vote_pred', vote_pred)\n",
    "#         print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "#         f = open('model_result/{modelname}.txt', 'a+')\n",
    "#         f.write('precision, recall, F1, acc= \\n')\n",
    "#         f.writelines(str(p))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(r))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(F1))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(acc))\n",
    "#         f.writelines('\\n')\n",
    "#         f.close()\n",
    "        \n",
    "        \n",
    "        vote_pred = np.zeros((1,testset.__len__()))\n",
    "        vote_score = np.zeros(testset.__len__())\n",
    "        print('vote_pred',vote_pred)\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open(f'model_result/test_{modelname}.txt', 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
